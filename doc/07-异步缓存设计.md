# OKTalk 发音纠正系统 - 缓存与异步处理架构设计文档

## 文档信息
- **版本**: v1.0
- **创建日期**: 2026-01-22
- **技术栈**: Golang (Gin) + MySQL + Redis
- **设计目标**: 高性能、高可用、用户体验优先

---

## 1. 整体架构设计理念

### 1.1 核心设计原则

**用户体验优先的分层响应策略**:
```
用户请求 → 立即返回基础评分 (2-3s) → 后台异步生成反馈 (3-4s) → WebSocket推送完整结果
```

**关键设计决策**:
1. **同步返回核心数据**: 讯飞评测结果（评分）必须同步返回，这是用户最关心的
2. **异步生成增值服务**: LLM反馈文本、TTS音频异步生成，通过WebSocket推送
3. **多级缓存策略**: Redis缓存热点数据，减少重复API调用
4. **失败优雅降级**: 异步任务失败不影响核心评分展示

---

## 2. Redis 缓存设计

### 2.1 Key Naming Convention

**命名规范**: `oktalk:{module}:{type}:{identifier}:{suffix}`

#### 示例:
```
oktalk:eval:result:eval_67890              # 评测完整结果
oktalk:demo:audio:word:apples              # 单词示范音频URL
oktalk:demo:audio:sentence:i_like_apples   # 句子示范音频URL
oktalk:user:quota:user_12345:20260122      # 用户每日配额
oktalk:temp:upload:abc123                  # 临时上传令牌
oktalk:feedback:text:eval_67890            # LLM反馈文本缓存
```

---

### 2.2 数据结构设计

#### 2.2.1 评测结果缓存 (Hash)

**Key**: `oktalk:eval:result:{evaluation_id}`  
**Type**: Hash  
**TTL**: 7天 (604800秒)

**字段结构**:
```redis
HSET oktalk:eval:result:eval_67890
  "user_id"              "user_12345"
  "target_text"          "I like apples"
  "overall_score"        "78"
  "accuracy_score"       "75"
  "fluency_score"        "82"
  "integrity_score"      "95"
  "feedback_level"       "B"
  "feedback_text"        "Good try! Let's practice..."
  "feedback_audio_url"   "https://cdn.oktalk.com/feedback/eval_67890.mp3"
  "demo_audio_url"       "https://cdn.oktalk.com/demo/word_apples.mp3"
  "demo_type"            "word"
  "created_at"           "2026-01-22T10:35:00Z"
  "status"               "completed"  # pending/processing/completed/failed
```

**使用场景**:
- 用户重复查看历史评测记录
- 前端轮询获取异步任务完成状态
- 避免重复调用讯飞API

---

#### 2.2.2 示范音频URL缓存 (String)

**Key**: 
- `oktalk:demo:audio:word:{normalized_word}`
- `oktalk:demo:audio:sentence:{normalized_sentence}`

**Type**: String  
**Value**: CDN URL  
**TTL**: 30天 (2592000秒)

**示例**:
```redis
SET oktalk:demo:audio:word:apples 
    "https://cdn.oktalk.com/demo/word_apples.mp3" 
    EX 2592000

SET oktalk:demo:audio:sentence:i_like_apples
    "https://cdn.oktalk.com/demo/sentence_i_like_apples.mp3"
    EX 2592000
```

**Normalization 规则**:
```go
func normalizeText(text string) string {
    // 转小写
    text = strings.ToLower(text)
    // 移除标点
    text = regexp.MustCompile(`[^\w\s]`).ReplaceAllString(text, "")
    // 空格替换为下划线
    text = strings.ReplaceAll(text, " ", "_")
    return text
}
```

**使用场景**:
- 避免对同一个单词/句子重复调用TTS API
- 高频词汇（如 "hello", "apple"）直接返回缓存URL

---

#### 2.2.3 用户配额限制 (String)

**Key**: `oktalk:user:quota:{user_id}:{date}`  
**Type**: String (计数器)  
**TTL**: 当天结束 (动态计算)

**示例**:
```redis
SET oktalk:user:quota:user_12345:20260122 "15" EX 3600
INCR oktalk:user:quota:user_12345:20260122
```

**使用场景**:
- 限制用户每日评测次数（如免费用户50次/天）
- 防止恶意刷接口

---

#### 2.2.4 临时上传令牌 (String)

**Key**: `oktalk:temp:upload:{token}`  
**Type**: String  
**Value**: JSON `{"user_id":"xxx","expires_at":"xxx"}`  
**TTL**: 5分钟 (300秒)

**示例**:
```redis
SET oktalk:temp:upload:abc123 
    '{"user_id":"user_12345","max_size":10485760}'
    EX 300
```

**使用场景**:
- 前端获取上传凭证
- 验证上传请求合法性

---

#### 2.2.5 LLM反馈文本缓存 (String)

**Key**: `oktalk:feedback:text:{score}:{problem_word}:{level}`  
**Type**: String  
**TTL**: 7天

**示例**:
```redis
SET oktalk:feedback:text:78:apples:B
    "Good try! Let's practice 'apples' together..."
    EX 604800
```

**使用场景**:
- 相似评分场景直接返回缓存文本，避免重复调用LLM
- 降低LLM API成本

---

### 2.3 缓存过期策略总结

| 数据类型 | TTL | 过期策略 | 理由 |
|---------|-----|---------|------|
| 评测结果 | 7天 | 固定过期 | 用户可能一周内多次查看 |
| 示范音频URL | 30天 | 固定过期 | 高频词汇长期有效 |
| 用户配额 | 当天结束 | 动态计算 | 每日限额自然重置 |
| 上传令牌 | 5分钟 | 固定过期 | 安全性要求 |
| LLM文本缓存 | 7天 | 固定过期 | 相似场景复用 |

---

## 3. 异步任务流程设计

### 3.1 同步与异步链路划分

#### 同步链路 (用户等待 2-3秒)
```
用户上传音频
   ↓
【同步】上传到临时存储 (OSS/本地)
   ↓
【同步】调用讯飞评测API
   ↓
【同步】解析评分数据
   ↓
【同步】保存基础评测记录到MySQL
   ↓
【同步】缓存评分到Redis (status=processing)
   ↓
立即返回HTTP响应给前端
{
  "evaluation_id": "eval_67890",
  "scores": {...},
  "status": "processing",  // 前端知道后台还在生成反馈
  "websocket_channel": "eval_67890"
}
```

#### 异步链路 (后台处理 3-5秒)
```
HTTP响应返回后
   ↓
【异步】创建Goroutine → Task Queue (Channel)
   ↓
Worker Pool 消费任务:
   ├─ Task 1: 调用LLM生成反馈文本 (1-2s)
   ├─ Task 2: 调用TTS生成反馈语音 (1-2s)
   └─ Task 3: [条件触发] 生成示范音频 (1-2s)
   ↓
【异步】上传音频到OSS
   ↓
【异步】更新MySQL记录
   ↓
【异步】更新Redis (status=completed)
   ↓
【异步】通过WebSocket推送完整结果给前端
```

---

### 3.2 Channel + Goroutine + Worker Pool 架构

#### 3.2.1 任务定义

```go
package async

import "time"

// TaskType 定义任务类型
type TaskType string

const (
    TaskGenerateFeedbackText  TaskType = "generate_feedback_text"
    TaskGenerateFeedbackAudio TaskType = "generate_feedback_audio"
    TaskGenerateDemoAudio     TaskType = "generate_demo_audio"
)

// EvaluationTask 评测异步任务
type EvaluationTask struct {
    ID            string                 // evaluation_id
    Type          TaskType               
    Priority      int                    // 优先级 (1=最高)
    Data          map[string]interface{} // 任务数据
    RetryCount    int                    // 当前重试次数
    MaxRetries    int                    // 最大重试次数
    CreatedAt     time.Time
    ExecuteAfter  time.Time              // 延迟执行时间(用于重试)
}

// TaskResult 任务执行结果
type TaskResult struct {
    TaskID    string
    Success   bool
    Data      map[string]interface{}
    Error     error
}
```

---

#### 3.2.2 Worker Pool 实现

```go
package async

import (
    "context"
    "log"
    "sync"
    "time"
)

// WorkerPool 异步任务工作池
type WorkerPool struct {
    workerCount   int
    taskQueue     chan *EvaluationTask
    resultQueue   chan *TaskResult
    wg            *sync.WaitGroup
    ctx           context.Context
    cancel        context.CancelFunc
    handlers      map[TaskType]TaskHandler
}

// TaskHandler 任务处理器接口
type TaskHandler interface {
    Handle(ctx context.Context, task *EvaluationTask) (*TaskResult, error)
}

// NewWorkerPool 创建工作池
func NewWorkerPool(workerCount, queueSize int) *WorkerPool {
    ctx, cancel := context.WithCancel(context.Background())
    return &WorkerPool{
        workerCount:   workerCount,
        taskQueue:     make(chan *EvaluationTask, queueSize),
        resultQueue:   make(chan *TaskResult, queueSize),
        wg:            &sync.WaitGroup{},
        ctx:           ctx,
        cancel:        cancel,
        handlers:      make(map[TaskType]TaskHandler),
    }
}

// RegisterHandler 注册任务处理器
func (p *WorkerPool) RegisterHandler(taskType TaskType, handler TaskHandler) {
    p.handlers[taskType] = handler
}

// Start 启动工作池
func (p *WorkerPool) Start() {
    // 启动worker goroutines
    for i := 0; i < p.workerCount; i++ {
        p.wg.Add(1)
        go p.worker(i)
    }
    
    // 启动结果处理器
    go p.resultProcessor()
    
    log.Printf("[WorkerPool] Started with %d workers", p.workerCount)
}

// worker 工作协程
func (p *WorkerPool) worker(id int) {
    defer p.wg.Done()
    
    for {
        select {
        case <-p.ctx.Done():
            log.Printf("[Worker-%d] Shutting down", id)
            return
            
        case task := <-p.taskQueue:
            // 检查是否需要延迟执行
            if time.Now().Before(task.ExecuteAfter) {
                time.Sleep(time.Until(task.ExecuteAfter))
            }
            
            // 执行任务
            result := p.executeTask(task)
            
            // 发送结果
            select {
            case p.resultQueue <- result:
            case <-p.ctx.Done():
                return
            }
        }
    }
}

// executeTask 执行任务
func (p *WorkerPool) executeTask(task *EvaluationTask) *TaskResult {
    handler, exists := p.handlers[task.Type]
    if !exists {
        return &TaskResult{
            TaskID:  task.ID,
            Success: false,
            Error:   fmt.Errorf("no handler for task type: %s", task.Type),
        }
    }
    
    // 执行任务
    result, err := handler.Handle(p.ctx, task)
    if err != nil {
        log.Printf("[Task-%s] Failed: %v (retry: %d/%d)", 
            task.ID, err, task.RetryCount, task.MaxRetries)
        
        // 判断是否需要重试
        if task.RetryCount < task.MaxRetries {
            p.retryTask(task)
        }
        
        return &TaskResult{
            TaskID:  task.ID,
            Success: false,
            Error:   err,
        }
    }
    
    return result
}

// retryTask 重试任务
func (p *WorkerPool) retryTask(task *EvaluationTask) {
    task.RetryCount++
    
    // 指数退避: 2^n 秒
    backoff := time.Duration(1<<uint(task.RetryCount)) * time.Second
    task.ExecuteAfter = time.Now().Add(backoff)
    
    log.Printf("[Task-%s] Scheduling retry in %v", task.ID, backoff)
    
    // 重新入队
    go func() {
        select {
        case p.taskQueue <- task:
        case <-p.ctx.Done():
        }
    }()
}

// resultProcessor 结果处理器
func (p *WorkerPool) resultProcessor() {
    for {
        select {
        case <-p.ctx.Done():
            return
            
        case result := <-p.resultQueue:
            if result.Success {
                // 更新Redis缓存
                // 更新MySQL
                // 发送WebSocket通知
                p.handleSuccess(result)
            } else {
                // 记录失败日志
                p.handleFailure(result)
            }
        }
    }
}

// Submit 提交任务
func (p *WorkerPool) Submit(task *EvaluationTask) error {
    select {
    case p.taskQueue <- task:
        return nil
    case <-time.After(5 * time.Second):
        return fmt.Errorf("task queue full")
    }
}

// Shutdown 优雅关闭
func (p *WorkerPool) Shutdown(timeout time.Duration) {
    log.Println("[WorkerPool] Shutting down...")
    
    p.cancel()
    
    // 等待所有worker完成
    done := make(chan struct{})
    go func() {
        p.wg.Wait()
        close(done)
    }()
    
    select {
    case <-done:
        log.Println("[WorkerPool] Shutdown completed")
    case <-time.After(timeout):
        log.Println("[WorkerPool] Shutdown timeout, forcing exit")
    }
}
```

---

#### 3.2.3 具体任务处理器

```go
package handlers

// FeedbackTextHandler LLM反馈文本生成
type FeedbackTextHandler struct {
    llmClient  *LLMClient
    redisCache *redis.Client
}

func (h *FeedbackTextHandler) Handle(ctx context.Context, task *async.EvaluationTask) (*async.TaskResult, error) {
    // 1. 检查缓存
    cacheKey := fmt.Sprintf("oktalk:feedback:text:%d:%s:%s",
        task.Data["score"],
        task.Data["problem_word"],
        task.Data["level"])
    
    if cached, err := h.redisCache.Get(ctx, cacheKey).Result(); err == nil {
        return &async.TaskResult{
            TaskID:  task.ID,
            Success: true,
            Data:    map[string]interface{}{"text": cached},
        }, nil
    }
    
    // 2. 调用LLM生成
    text, err := h.llmClient.GenerateFeedback(ctx, task.Data)
    if err != nil {
        return nil, err
    }
    
    // 3. 缓存结果
    h.redisCache.Set(ctx, cacheKey, text, 7*24*time.Hour)
    
    return &async.TaskResult{
        TaskID:  task.ID,
        Success: true,
        Data:    map[string]interface{}{"text": text},
    }, nil
}

// FeedbackAudioHandler TTS反馈语音生成
type FeedbackAudioHandler struct {
    ttsClient *TTSClient
    ossClient *OSSClient
}

func (h *FeedbackAudioHandler) Handle(ctx context.Context, task *async.EvaluationTask) (*async.TaskResult, error) {
    // 1. 调用TTS
    audioData, err := h.ttsClient.Synthesize(ctx, task.Data["text"].(string))
    if err != nil {
        return nil, err
    }
    
    // 2. 上传到OSS
    url, err := h.ossClient.Upload(ctx, audioData, fmt.Sprintf("feedback/%s.mp3", task.ID))
    if err != nil {
        return nil, err
    }
    
    return &async.TaskResult{
        TaskID:  task.ID,
        Success: true,
        Data:    map[string]interface{}{"audio_url": url},
    }, nil
}

// DemoAudioHandler 示范音频生成
type DemoAudioHandler struct {
    ttsClient  *TTSClient
    ossClient  *OSSClient
    redisCache *redis.Client
}

func (h *DemoAudioHandler) Handle(ctx context.Context, task *async.EvaluationTask) (*async.TaskResult, error) {
    demoText := task.Data["demo_text"].(string)
    demoType := task.Data["demo_type"].(string) // "word" or "sentence"
    
    // 1. 检查缓存
    normalizedText := normalizeText(demoText)
    cacheKey := fmt.Sprintf("oktalk:demo:audio:%s:%s", demoType, normalizedText)
    
    if cachedURL, err := h.redisCache.Get(ctx, cacheKey).Result(); err == nil {
        return &async.TaskResult{
            TaskID:  task.ID,
            Success: true,
            Data:    map[string]interface{}{"demo_audio_url": cachedURL},
        }, nil
    }
    
    // 2. 生成TTS
    audioData, err := h.ttsClient.Synthesize(ctx, demoText)
    if err != nil {
        return nil, err
    }
    
    // 3. 上传OSS
    objectKey := fmt.Sprintf("demo/%s/%s.mp3", demoType, normalizedText)
    url, err := h.ossClient.Upload(ctx, audioData, objectKey)
    if err != nil {
        return nil, err
    }
    
    // 4. 缓存URL
    h.redisCache.Set(ctx, cacheKey, url, 30*24*time.Hour)
    
    return &async.TaskResult{
        TaskID:  task.ID,
        Success: true,
        Data:    map[string]interface{}{"demo_audio_url": url},
    }, nil
}
```

---

### 3.3 主流程集成

```go
// EvaluationService 评测服务
type EvaluationService struct {
    iflytek    *IFlytekClient
    workerPool *async.WorkerPool
    redis      *redis.Client
    db         *gorm.DB
    wsHub      *websocket.Hub
}

func (s *EvaluationService) Evaluate(ctx context.Context, req *EvaluateRequest) (*EvaluateResponse, error) {
    // ========== 同步部分 ==========
    
    // 1. 调用讯飞评测API (带重试)
    scoreData, err := s.callIFlytekWithRetry(ctx, req.AudioData, req.TargetText)
    if err != nil {
        return nil, err
    }
    
    // 2. 生成evaluation_id
    evalID := fmt.Sprintf("eval_%d", time.Now().UnixNano())
    
    // 3. 保存基础评测记录到MySQL
    evaluation := &models.Evaluation{
        ID:            evalID,
        UserID:        req.UserID,
        TargetText:    req.TargetText,
        OverallScore:  scoreData.OverallScore,
        AccuracyScore: scoreData.AccuracyScore,
        // ... 其他字段
        Status:        "processing",
    }
    s.db.Create(evaluation)
    
    // 4. 缓存到Redis
    s.cacheEvaluationResult(ctx, evaluation)
    
    // 5. 立即返回HTTP响应
    response := &EvaluateResponse{
        EvaluationID: evalID,
        Scores:       scoreData,
        Status:       "processing",
        WebSocketChannel: evalID,
    }
    
    // ========== 异步部分 ==========
    
    // 6. 提交异步任务
    go s.submitAsyncTasks(evalID, scoreData)
    
    return response, nil
}

func (s *EvaluationService) submitAsyncTasks(evalID string, scoreData *ScoreData) {
    // Task 1: 生成反馈文本
    s.workerPool.Submit(&async.EvaluationTask{
        ID:         evalID,
        Type:       async.TaskGenerateFeedbackText,
        Priority:   1,
        MaxRetries: 3,
        Data: map[string]interface{}{
            "score":         scoreData.OverallScore,
            "problem_word":  scoreData.ProblemWords[0],
            "level":         scoreData.FeedbackLevel,
            "target_text":   scoreData.TargetText,
        },
    })
    
    // Task 2: 生成反馈语音 (依赖Task 1完成)
    // 实际实现中可以通过Pipeline模式处理依赖
    
    // Task 3: 生成示范音频 (条件触发)
    if scoreData.OverallScore < 90 {
        s.workerPool.Submit(&async.EvaluationTask{
            ID:         evalID,
            Type:       async.TaskGenerateDemoAudio,
            Priority:   2,
            MaxRetries: 3,
            Data: map[string]interface{}{
                "demo_text": scoreData.ProblemWords[0],
                "demo_type": "word",
            },
        })
    }
}
```

---

## 4. 失败重试策略

### 4.1 讯飞API同步调用重试

```go
package client

import (
    "context"
    "fmt"
    "time"
)

// IFlytekClient 讯飞客户端
type IFlytekClient struct {
    apiKey    string
    baseURL   string
    maxRetries int
}

// EvaluateWithRetry 带重试的评测调用
func (c *IFlytekClient) EvaluateWithRetry(ctx context.Context, audioData []byte, text string) (*ScoreData, error) {
    var lastErr error
    
    for attempt := 0; attempt <= c.maxRetries; attempt++ {
        if attempt > 0 {
            // 指数退避: 100ms * 2^attempt
            backoff := time.Duration(100<<uint(attempt-1)) * time.Millisecond
            log.Printf("[IFlytek] Retry %d/%d after %v", attempt, c.maxRetries, backoff)
            
            select {
            case <-time.After(backoff):
            case <-ctx.Done():
                return nil, ctx.Err()
            }
        }
        
        // 调用API
        result, err := c.evaluate(ctx, audioData, text)
        if err == nil {
            return result, nil
        }
        
        lastErr = err
        
        // 判断是否可重试
        if !isRetriableError(err) {
            return nil, fmt.Errorf("non-retriable error: %w", err)
        }
    }
    
    return nil, fmt.Errorf("max retries exceeded: %w", lastErr)
}

// isRetriableError 判断错误是否可重试
func isRetriableError(err error) bool {
    // 网络超时、5xx错误可重试
    // 4xx客户端错误不可重试
    switch {
    case isNetworkError(err):
        return true
    case isServerError(err): // 5xx
        return true
    case isClientError(err): // 4xx
        return false
    default:
        return false
    }
}
```

**重试配置**:
- **最大重试次数**: 3次
- **退避策略**: 指数退避 (100ms, 200ms, 400ms)
- **总超时**: 5秒 (context.WithTimeout)

---

### 4.2 异步任务重试策略

| 任务类型 | 最大重试次数 | 退避策略 | 失败处理 |
|---------|-------------|---------|---------|
| LLM生成文本 | 3次 | 2^n 秒 (2s, 4s, 8s) | 使用降级模板 |
| TTS生成反馈音频 | 3次 | 2^n 秒 | 标记失败,不提供音频 |
| TTS生成示范音频 | 2次 | 2^n 秒 | 标记失败,提示用户稍后重试 |

**降级策略**:
```go
// LLM失败后使用模板
var fallbackTemplates = map[string]string{
    "S": "Perfect! Your pronunciation is excellent!",
    "A": "Very good! Keep practicing to make it even better.",
    "B": "Good try! Let's practice the difficult words together.",
    "C": "Keep going! Listen to the demo and try again.",
}

func (h *FeedbackTextHandler) handleLLMFailure(level string) string {
    return fallbackTemplates[level]
}
```

---

## 5. 配置参数建议

### 5.1 Worker Pool 配置

```yaml
worker_pool:
  worker_count: 10           # Worker数量 (根据CPU核心数调整)
  queue_size: 1000          # 任务队列大小
  shutdown_timeout: 30s     # 优雅关闭超时
```

**选型依据**:
- 预估QPS: 100/s
- 每个任务平均耗时: 3秒
- 所需Worker数: 100 * 3 / 10 = 30 (留余量取10)

---

### 5.2 Redis 连接池

```yaml
redis:
  host: localhost:6379
  db: 0
  pool_size: 50             # 连接池大小
  min_idle_conns: 10        # 最小空闲连接
  max_retries: 3            # 命令重试次数
  dial_timeout: 5s
  read_timeout: 3s
  write_timeout: 3s
```

---

### 5.3 外部API超时配置

```yaml
external_apis:
  iflytek:
    timeout: 5s
    max_retries: 3
    
  llm_qwen:
    timeout: 10s
    max_retries: 3
    
  tts_cosyvoice:
    timeout: 8s
    max_retries: 3
    
  oss_upload:
    timeout: 30s
    max_retries: 2
```

---



## 6. 失败场景与降级方案

| 失败场景 | 检测方式 | 降级方案 | 用户体验 |
|---------|---------|---------|---------|
| 讯飞API不可用| 3次重试后失败 | 返回错误,提示稍后重试 | 显示"评测服务暂时不可用" |
| LLM生成超时 | 10秒超时 | 使用模板反馈 | 用户看到标准反馈文本 |
| TTS生成失败 | 3次重试后失败 | 仅返回文本反馈 | 显示文字,音频标记为"生成中" |
| OSS上传失败 | 2次重试后失败 | 保存本地,异步重传 | 暂时显示占位符 |
| Redis不可用 | 连接失败 | 直接调用API,不缓存 | 响应变慢但功能正常 |

7. 总结
7.1 架构优势

用户体验优先: 2-3秒返回核心评分,异步生成增值内容
高性能: Redis多级缓存减少80%+ API调用
高可用: 失败重试 + 降级策略保证核心功能
可扩展: Worker Pool可动态调整,支持水平扩展

7.2 关键技术点

✅ Channel + Goroutine实现异步任务队列
✅ 指数退避重试策略
✅ Redis多数据结构缓存设计
✅ WebSocket实时推送完成状态
✅ 优雅降级保证核心功能